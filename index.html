<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Osher Azulay</title>

    <meta name="author" content="Osher Azulay">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center">
                  Osher Azulay
                </p>
                <p> Iâ€™m a passionate roboticist pursuing my PhD studies at the <a href="https://robotics.eng.tau.ac.il/">ROB-TAU Robotics Lab</a> within the MechEng Dept. at Tel-Aviv University. My research centers primarily on understanding how robots learn to sense their environment, with a focus on robotic manipulations, intelligent decision-making, and tactile sensing.
                   </p><p> Find my latest work here, feel free to contact me for any questions!</p>
                <p style="text-align:center">
                  <a href="mailto:azulayosher@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Osher-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=XQdRWyUAAAAJ&hl=iw">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/osher-azulay-20ab38154/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/osheraz">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/OsherAzulay-modified.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/OsherAzulay-modified.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, machine learning, optimization, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table> -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <!-- Example with video update over mouse motion -->
    <!-- <tr onmouseout="camp_stop()" onmouseover="camp_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='camp_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/camp.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/camp.png' width="160">
        </div>
        <script type="text/javascript">
          function camp_start() {
            document.getElementById('camp_image').style.opacity = "1";
          }

          function camp_stop() {
            document.getElementById('camp_image').style.opacity = "0";
          }
          camp_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://camp-nerf.github.io/">
          <span class="papertitle">CamP: Camera Preconditioning for Neural Radiance Fields</span>
        </a>
        <br>
        <a href="https://keunhong.com/">Keunhong Park</a>,
        <a href="https://henzler.github.io/">Philipp Henzler</a>,
        <a href="https://bmild.github.io/">Ben Mildenhall</a>,
        <strong>Jonathan T. Barron</strong>,
        <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>
        <br>
        <em>SIGGRAPH Asia</em>, 2023
        <br>
        <a href="https://camp-nerf.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2308.10902">arXiv</a>
        <p></p>
        <p>
        Preconditioning based on camera parameterization helps NeRF and camera extrinsics/intrinsics optimize better together.
        </p>
      </td>
    </tr> -->
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/visoutactile.gif" alt="vt" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2411.06408">
          <span class="papertitle">Visuotactile-Based Learning for Insertion with Compliant Hands</span>
        </a>
        <br>
          <strong>Osher Azulay</strong>, <a href="https://scholar.google.com/citations?user=OTJtuB4AAAAJ&hl=en">Dhruv Metha Ramesh</a>,
          <a href="https://nimicurtis.github.io/">Nimrod Curtis</a> and <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em> Preprint</em>.
        <br>
        <a href="https://arxiv.org/abs/2411.06408">paper</a>
        /
        <a href="https://github.com/osheraz/IsaacGymInsertion">code</a>
        <p></p>
        <p>Sim2real learning of robust precision insertion polices with compliant hands.</p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/aug.png" alt="ag" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2309.10409">
          <span class="papertitle">Augmenting Tactile Simulators with Real-like and Zero-Shot Capabilities</span>
        </a>
        <br>
          <strong>Osher Azulay</strong>*, <a href="https://www.linkedin.com/in/alon-mizrahi-4978a2238/">Alon Mizrahi</a>*,
          <a href="https://www.linkedin.com/in/nimrod-curtis/?originalSubdomain=il">Nimrod Curtis</a>* and <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em>ICRA 2024</em>.
        <br>
        <a href="https://arxiv.org/abs/2309.10409">paper</a>
        /
        <a href="https://github.com/RobLab-Allsight/allsight_sim2real">code</a>
        <p></p>
        <p>Tackling the sim-to-real problem for high resolution 3D round sensors using bi-directional Generative Adversarial Networks.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/allsight.gif" alt="allsight" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2307.02928">
          <span class="papertitle">AllSight: A Low-Cost and High-Resolution Round Tactile Sensor with Zero-Shot Learning Capability</span>
        </a>
        <br>
           <strong>Osher Azulay</strong>,
           <a href="https://www.linkedin.com/in/nimrod-curtis/?originalSubdomain=il">Nimrod Curtis</a>, Rotem Sokolovsky, Guy Levitski, Daniel Slomovik, Guy Lilling and
           <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em>IEEE RA-L & ICRA</em>, 2024.
        <br>
        <a href="https://arxiv.org/abs/2307.02928">paper</a>
        /
        <a href="https://www.youtube.com/watch?v=Cv90pMow7SI&ab_channel=AvishaiSintov">video</a>
        /
        <a href="https://github.com/osheraz/allsight">code</a>
        <p></p>
        <p> Introducing <em>AllSight</em>, an optical tactile sensor with a round 3D structure designed for robotic inhand manipulation tasks</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/se3.gif" alt="hapticrl" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9963587">
          <span class="papertitle">Haptic-Based and SE(3)-Aware Object Insertion Using Compliant Hands</span>
        </a>
        <br>
          <strong>Osher Azulay</strong>, <a href="https://www.linkedin.com/in/max-monastirsky/?originalSubdomain=il">Max Monastirsky</a> and <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em>IEEE RA-L & ICRA</em>, 2023.
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/9963587">paper</a>
        /
        <a href="https://www.youtube.com/watch?v=arA6Klb5KpM&ab_channel=AvishaiSintov">video</a>
        <p></p>
        <p>Exploring complaint hands characteristics for object insertion using haptic-based residual RL.</p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/throw.png" alt="throw" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://ieeexplore.ieee.org/document/9984828">
          <span class="papertitle">Learning to Throw With a Handful of Samples Using Decision Transformers</span>
        </a>
        <br>
          <a href="https://www.linkedin.com/in/max-monastirsky/?originalSubdomain=il">Max Monastirsky</a>, <strong>Osher Azulay</strong> and <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em>IEEE RA-L & IROS</em>, 2023.
        <br>
        <a href="https://ieeexplore.ieee.org/document/9984828">paper</a>
        /
        <a href="https://www.youtube.com/watch?v=5_G6o_H3HeE&ab_channel=AvishaiSintov">video</a>
        <p></p>
        <p>Exploring the use of Decision Transformers for throwing and their ability for sim2real policy transfer.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/haptic.gif" alt="hapticmpc" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://arxiv.org/abs/2207.02843">
          <span class="papertitle">Learning Haptic-based Object Pose Estimation for In-hand Manipulation Control with Underactuated Robotic Hands</span>
        </a>
        <br>
          <strong>Osher Azulay</strong>, <a href="https://www.linkedin.com/in/inbar-meir-12773a8a/">Inbar Meir</a> and <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em>IEEE Transactions on Haptics</em>, 2022.
        <br>
        <a href="https://arxiv.org/abs/2207.028437">paper</a>
        /
        <a href="https://www.youtube.com/watch?v=aDdgix1BU5o&ab_channel=AvishaiSintov">video</a>
        /
        <a href="https://github.com/osheraz/haptic_pose_estimation">code</a>
        <p></p>
        <p>In-hand object pose estimation and manipulation using Model Predictive Control.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/open.gif" alt="ops" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://neurips.cc/virtual/2021/workshop/38185">
          <span class="papertitle">Open-Sourcing Generative Models for Data-driven Robot Simulations</span>
        </a>
        <br>
        <a href="https://eranbamani.github.io/eranbamani/">Eran Bamani</a>, <strong>Osher Azulay</strong>, Anton Gurevich, and <a href="http://web2.eng.tau.ac.il/wtest/Avishailab/index.php/sintov/">Avishai Sintov</a>.
        <br>
        <em>Data-Centric AI workshop, NeurIPS</em>, 2021
        <br>
        <a href="data/NeurIPS2021_Data_centric_AI.pdf">paper</a>
        /
        <a href="https://neurips.cc/virtual/2021/workshop/38185">oral</a>
        <p></p>
        <p>Exploring the possibility of investing the recorded data in a generative model rather than directly to a regression model for real-robot applications.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/komodo.gif" alt="komodo" width="260" height="160">
      </td>
      <td width="75%" valign="middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/9344588/">
          <span class="papertitle">Wheel Loader Scooping Controller Using Deep Reinforcement Learning</span>
        </a>
        <br>
        <strong>Osher Azulay</strong> and <a href="https://www.linkedin.com/in/amir-shapiro-b935a63/?originalSubdomain=il">Amir Shapiro.</a>
        <br>
        <em>IEEE Access</em>, 2021
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/9344588/">paper</a>
        /
        <a href="https://www.youtube.com/watch?v=pYX7Ppq_PY4&ab_channel=OsherAzulay">video</a>
        /
        <a href="https://github.com/osheraz/komodo">code</a>
        <p></p>
        <p>A deep reinforcement learning-based controller for an unmanned ground vehicle with a custom-built scooping mechanism.</p>
      </td>
    </tr>

  </tbody></table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table> -->
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

            <!-- <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr> -->

            <tr>
              <td align="center" style="padding:20px;width:10%;vertical-align:middle">
                <h2>Talks, Honor & <br> Recognition</h2>
              </td>
              <td width="75%" valign="middle">
                <ul>
                <li>Fulbright Postdoctoral Fellowship to pursue research @ UCBerkeley.</li>
                <li>Nehemia Levtzion Scholarship for PhD excellence.</li>
                <li>The Mechanical Engineering Graduate Research Award.</li>
                <li>KLA Scholarships for PhD excellence, 2023 & 2024 </li>
                <li>Deanâ€™s Excellence in Teaching award, 2022.</li>
                <li>Invited to talk @ Annual meeting for Motion Control and Automation, Expo Tel-Aviv, 2021.</li>
                <li>Student Honor List: 2017-2018, 2018-2019.</li>
                </ul>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template from <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
